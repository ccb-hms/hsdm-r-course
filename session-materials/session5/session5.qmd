---
title: "Week 5: Exploratory analysis and basic tests"
format: 
  html: default
code-annotations: select
---

```{r}
library(tidyverse)
library(DT)
```

# Data

We can load our processed NHANES data from last week. 

```{r}
nhanes <- read_csv("../session4/nhanes_processed.csv")
```

# Making tables

For some data, we might want to visualize things with a table instead of a plot. 
We can use the `table` builtin function to easily tabulate age by dental caries. 

```{r}
table(nhanes[,c("RIDAGEYR","dental.caries")])
```
However, we can also take advantage of packages written for this purpose. 
For instance, we can quickly make a frequency table using the `proc_freq` function in `flextable`. 

```{r}
# install.packages("flextable")
library(flextable)
proc_freq(nhanes,"RIDAGEYR","dental.caries")
```

Or we can use the `gtsummary` package to summarize everything.

```{r}
library(gtsummary)

select(nhanes,dental.caries, age.cat, bmi.cat, hba1c.cat, birthplace, diabetes) %>%
  tbl_summary(by = dental.caries)
```

# Summary statistics or visualization?

Summary statistics can compress datasets of any size into just a few numbers. 
This can be vital for understanding large amounts of data, but can also lead to misconceptions.
Let's take a look at a classic example, Anscombe's quartet. 

```{r}
library(datasets)
datasets::anscombe
```

First, we need to restructure this data so we can easily group it by each of the different 4 datasets included. 
This uses the `pivot_longer` command to reshape the data, which we will not be covering in-class but is mentioned in the readings. 

```{r}
# Let's restructure this data to have 3 variables, x, y, and the dataset number it belongs to
long_ans <- anscombe |>
  pivot_longer(
    everything(),
    cols_vary = "slowest",
    names_to = c(".value", "set"),
    names_pattern = "(.)(.)"
  )

```

Now we can visualize the 4 datasets easily using a `facet_wrap` in ggplot:

```{r}
ggplot(long_ans,aes(x=x,y=y,group=set))+geom_point()+facet_wrap(~set)
```
::: {.callout-tip appearance="minimal"}
# Exercise 

Calculate the mean and variance for x and y, and the correlation between x and y of each of the 4 sets of data. 

```{r}
long_ans |>
  group_by(set) |>
  summarise(mean_x = mean(x), mean_y = mean(y), variance_x = var(x), variance_y = var(y), correlation = cor(x, y))
```

:::

### Datasaurus

A similar example is in the `datasauRus` package in R. 

```{r}
library(datasauRus)

datasaurus_dozen |> 
  group_by(dataset) |> 
  summarize(
    mean_x    = mean(x),
    mean_y    = mean(y),
    std_dev_x = sd(x),
    std_dev_y = sd(y),
    corr_x_y  = cor(x, y)
  )
```

```{r}
library(ggplot2)
ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+
  geom_point()+
  theme_void()+
  theme(legend.position = "none")+
  facet_wrap(~dataset, ncol = 3)
```


# Performing simple tests

Let's start by looking at the relationship between ethnicity and dental caries using the `table` command. 

```{r}
table(nhanes$RIDRETH1, nhanes$dental.caries)
```
We can group and summarize the data to take a look at percents by group instead:
```{r}
eth_ado <- nhanes %>%
  group_by(RIDRETH1, dental.caries) %>%
  summarise(count = n()) %>%
  mutate(perc = count/sum(count))
eth_ado
```

We could also visualize the different distributions:
```{r}
ggplot(filter(eth_ado, dental.caries == TRUE), aes(x = RIDRETH1, y = perc*100)) + 
    geom_bar(stat = "identity") + 
    theme(axis.text.x = element_text(angle = 45, hjust=1)) +
    labs(x = "Ethnicity", y = "Percent Dental Caries")
```
We can also perform a Chi-squared test to examine the relationship between the variables. 
We either print the result directly or store it in a variable and examine it's different components. 

```{r}
res <- chisq.test(table(nhanes$RIDRETH1, nhanes$dental.caries))

res$method
res$p.value
res$statistic
```

# Calculating statistics by group

Many data analysis tasks can be approached using the
*split-apply-combine* paradigm: split the data into groups, apply some
analysis to each group, and then combine the results. **`dplyr`**
makes this very easy through the use of the `group_by()` function.

```{r}
nhanes %>%
  group_by(birthplace)
```

The `group_by()` function doesn't perform any data processing, it
groups the data into subsets: in the example above, our initial
`tibble` of `r nrow(nhanes)` observations is split into
`r length(unique(nhanes$birthplace))` groups based on the `birthplace` variable.

We could similarly decide to group the tibble by sex:

```{r}
nhanes %>%
  group_by(RIAGENDR)
```

Here our initial `tibble` of `r nrow(nhanes)` observations is split into
`r length(unique(nhanes$sex))` groups based on the `sex` variable.

Once the data has been grouped, subsequent operations will be
applied on each group independently.

### The `summarise()` function

`group_by()` is often used together with `summarise()`, which
collapses each group into a single-row summary of that group.

`group_by()` takes as arguments the column names that contain the
**categorical** variables for which you want to calculate the summary
statistics. So to compute the mean `bmi` by birthplace:

```{r}
nhanes %>%
  group_by(birthplace) %>%
  summarise(mean_bmi = mean(BMXBMI, na.rm = TRUE))
```

But we can can also group by multiple columns:

```{r}
nhanes %>%
  group_by(BMXBMI, RIDRETH1) %>%
  summarise(mean_bmi = mean(BMXBMI, na.rm = TRUE))
```

Once the data is grouped, you can also summarise multiple variables at the same
time (and not necessarily on the same variable). For instance, we could add
columns indicating the mean and median plasma glucose (`LBXGLU`) by sex and ethnicity:

```{r}
nhanes %>%
  group_by(RIDAGEYR, age.cat, RIDRETH1) %>%
  summarise(mean_plasma_glucose = mean(LBXGLU, na.rm = TRUE),
            median_plasma_glucose = median(LBXGLU, na.rm = TRUE))
```

::: {.callout-note icon=false}

## Challenge

Calculate the mean `hba1c` of participants born in the USA by age.

:::


::: {.callout-tip icon=false collapse=true}

## Solution

```{r}
nhanes %>%
  filter(birthplace == 'Within the US') %>%
  group_by(age.cat) %>%
  summarise(mean_hba1c = mean(LBXGH, na.rm = TRUE))
```

:::

### Counting

When working with data, we often want to know the number of observations found
for each factor or combination of factors. For this task, **`dplyr`** provides
`count()`. For example, if we wanted to count the number of rows of data for
each age, we would do:

```{r}
nhanes %>%
    count(RIDAGEYR)
```

The `count()` function is shorthand for something we've already seen: grouping by a variable, and summarising it by counting the number of observations in that group. In other words, `nhanes %>% count(age.years)` is equivalent to:

```{r}
nhanes %>%
    group_by(age.cat) %>%
    summarise(n = n())
```

The previous example shows the use of `count()` to count the number of rows/observations
for *one* factor (i.e., `infection`).
If we wanted to count a *combination of factors*, such as `age` and `sex`,
we would specify the first and the second factor as the arguments of `count()`:

```{r}
nhanes %>%
    count(RIDAGEYR, RIAGENDR)
```

::: {.callout-note icon=false}

## Challenge

1. How many participants have a non-empty plasma glucose value for each age (using `RIDAGEYR`)?
2. Use `group_by()` and `summarise()` to evaluate BMI (`BMXBMI`) by ethnicity. Which ethnicity has the highest mean BMI?

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r}
#1
nhanes %>% filter(!is.na(LBXGLU)) %>%
  group_by(RIDAGEYR) %>%
  count()

#2
nhanes %>% group_by(RIDRETH1) %>%
  summarise(mean_BMI = mean(BMXBMI, na.rm = TRUE)) %>%
  arrange(desc(mean_BMI))
```


:::

## Analyzing the adolescent data

As we just saw, we can use `group_by` and `summarize` to see summary statistics by various subgroups. 
For instance, let's take a look at dental caries and birthplace. 

```{r}
nhanes |>
  group_by(dental.caries, birthplace) |>
  summarize(n = n())
```
::: {.callout-tip appearance="minimal"}
## Summarizing

Calculate the percent of adolescents with dental caries for each birthplace category. 

```{r}
nhanes |>
  group_by(birthplace) |> # Group by birthplace
  summarize(n = n(), caries = sum(dental.caries)) |>
  mutate(perc_caries = caries/n)
```
:::

### Insulin

Let's look at the demographics of who's taking insulin by birthplace and family income. 

```{r}
nhanes |>
  filter(diabetes == "diabetic") |>
  group_by(birthplace, family.PIR.cat) |> 
  summarize(n = n(), insulin = sum((DIQ050) == "Yes")) |>
  mutate(perc_insulin = insulin/n)
```

We can also take a look at ethnicity.
Let's split this into two steps. 
First we make a table containing summarized data.
```{r}
insulin_tbl <- nhanes |>
  filter(diabetes == "diabetic") |>
  group_by(RIDRETH1, birthplace) |> 
  summarize(n = n(), insulin = sum((DIQ050) == "Yes"), na.rm=TRUE) |>
  mutate(perc_insulin = insulin/n)
```
And now we can plot it. 
```{r}
ggplot(insulin_tbl, aes(x = birthplace, y = perc_insulin)) + 
  geom_bar(stat = "identity") + 
  facet_grid(~RIDRETH1)
```
Unfortunately, it turns out insulin data is quite sparse for adolescents in the dataset. 
Thus, we can't really get a good picture of insulin use within our study population. 
This is probably why this data was not included in the paper's analysis. 
