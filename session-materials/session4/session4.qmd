---
title: "Week 4: Preparing Data"
author: "Center for Computational Biomedicine"
format: 
  html: default
code-annotations: select
---

```{r}
library(tidyverse)
```

# Data

This week we are going to start learning how to get to the cleaned data we have been using for the past two weeks. 

Note that this week the data is in the `.RData` format.
The `.RData` format is specific to R and allows us to easily dump multiple objects to a file exactly as the are inside of our R session. 
This format is not recommended for research as it limits analyses to only using R and could potentially not be compatible with a future R version. 
However, for today it will allow us to jump right into the data cleaning process. 

The `nhanes_beheshti_data.RData` file contains 3 separate dataframes, `base_df_d`, `base_df_e`, and `base_df_f`.
They each contain the equivalent set of columns from the `D`, `E`, and `F` NHANES data files for 2005-2006, 2007-2008, and 2009-2010, respectively.  

Let's load and take a look at the data.

```{r}
load("nhanes_beheshti_data.RData")
```
```{r}
summary(base_df_d)
```
```{r}
summary(base_df_e)
```
```{r}
summary(base_df_f)
```



::: {.callout-info collapse="true"}
## See more about how we downloaded the data

The NHANES data was downloaded using a packaged called `phonto`.
`phonto` connects to a database of the NHANES data developed by the Center for Computational Biomedicine (CCB).
The database is a relational database running on a virtual machine using the containerization software [Docker](https://www.docker.com/). 

We will be learning a bit more about this in the last week of class.
The code used to download the data is shown here:

```r
library(phonto)

cols_d = list(DEMO_D=c("RIDAGEYR","RIAGENDR","RIDRETH1", 
                       "DMDBORN", "INDFMPIR", "SDMVPSU", "SDMVSTRA",
                       "WTINT2YR", "WTMEC2YR"), 
              OHX_D =c("OHXDECAY", "OHXREST"),
              GLU_D =c("LBXGLU", "WTSAF2YR"), GHB_D = "LBXGH",
              BMX_D="BMXBMI"
)
base_df_d <- jointQuery(cols_d)

cols_e = list(DEMO_E=c("RIDAGEYR","RIAGENDR","RIDRETH1",
                       "DMDBORN2", "INDFMPIR", "SDMVPSU", "SDMVSTRA",
                       "WTINT2YR", "WTMEC2YR"), 
              OHX_E =c("OHXDECAY", "OHXREST"),
              GLU_E =c("LBXGLU", "WTSAF2YR"), GHB_E = "LBXGH",
              BMX_E ="BMXBMI"
)
base_df_e <- jointQuery(cols_e)

cols_f = list(DEMO_F=c("RIDAGEYR","RIAGENDR","RIDRETH1",
                       "DMDBORN2", "INDFMPIR", "SDMVPSU", "SDMVSTRA",
                       "WTINT2YR", "WTMEC2YR"), 
              OHXDEN_F =c("OHXDECAY", "OHXREST"),
              GLU_F =c("LBXGLU", "WTSAF2YR"), GHB_F = "LBXGH",
              BMX_F ="BMXBMI"
)
base_df_f <- jointQuery(cols_f)

all_cols <- c(cols_d, cols_e, cols_f)
metadata <- dataDescription(all_cols)
save(base_df_d, base_df_e, base_df_f, metadata, file = "nhanes_beheshti_data.RData")
```
:::


# Preparing the data

In the reading, we saw how to combine multiple sets of observations by appending datasets. However, before we need to make sure corresponding columns between years can be combined. 

NHANES will often change how it encodes or records different variables from year to year.
Our first red flag are any columns whose name has changed.
Let's take a look at the column names.

```{r}
colnames(base_df_d)
colnames(base_df_e)
colnames(base_df_f)
```

We can also check for equality directly:

```{r}
colnames(base_df_d)[colnames(base_df_d) != colnames(base_df_e)]
colnames(base_df_e)[colnames(base_df_e) != colnames(base_df_f)]
colnames(base_df_f)[colnames(base_df_f) != colnames(base_df_d)]
```

It looks like `DMDBORN` changed after 2006 to `DMDBORN2`. 
If we check the demographic variable definitions for the three collection cycles [DEMO_D](https://wwwn.cdc.gov/nchs/nhanes/2005-2006/DEMO_D.htm#DMDBORN), [DEMO_E](https://wwwn.cdc.gov/Nchs/Nhanes/2007-2008/DEMO_E.htm#DMDBORN2), and [DEMO_F](https://wwwn.cdc.gov/Nchs/Nhanes/2009-2010/DEMO_F.htm#DMDBORN2) we can see that the encoding has changed over time.

To continue the analysis, let's also convert these dataframes into tibbles so we can take advantage of Tidyverse functionality. 

```{r}
tib_d <- as_tibble(base_df_d)
tib_e <- as_tibble(base_df_e)
tib_f <- as_tibble(base_df_f)
```

Let's also view the metadata of the columns.

```{r}
DT::datatable(metadata)
```


::: {.callout-tip appearance="minimal"}
## Exercise
a. Resolve the change the variable coding between the datasets.
Use your own judgement on the best way to resolve this issue. 

```{r}

# Step 1: Change things to have the same sets of values
# TODO your code here

# Step 2: Rename the columns to fit between the datasets
tib_e <- rename(tib_e, DMDBORN = DMDBORN2)
tib_f <- rename(tib_f, DMDBORN = DMDBORN2)
```

b. Check table 1b to see how the authors chose to handle this in [Beheshti et. al. 2021](https://pubmed.ncbi.nlm.nih.gov/33892837/). Do you think there were any other factors which went into their decision?

:::

## Combining the data

Now we can combine the data together.

```{r}
# Combine all years together
tib_all <- bind_rows(tib_d, tib_e, tib_f)
```


# Data cleaning pipeline

We can choose to leave the variables with their NHANES column names or change them to be a bit more human-readable. 
Either way, we also want to convert each variable to it's appropriate type or category. 

## Numeric variables
Let's start by converting numeric columns:

```{r}
# Set numeric columns to be numeric
tib_all <- mutate(tib_all,
                   RIDAGEYR = as.numeric(RIDAGEYR),
                   LBXGLU = as.numeric(LBXGLU),
                   LBXGH = as.numeric(LBXGH),
                   BMXBMI = as.numeric(BMXBMI))
```

## Categorical variables

Many of the NHANES values are are categorical data, bur right now are stored as text. 
We can check what values exist by converting them to factors before making the decision of how to handle them in the analysis: 

```{r}
tib_all |>
  mutate(across(c(RIAGENDR, RIDRETH1, DMDBORN), as.factor), .keep = "none") |>
  summary()
```

It looks like one of the options for `DMDBORN` has a lingering quote character.
This can happen due to irregularities in how NHANES data is presented or small mistakes in data processing. 
We use the `gsub` function to replace all instances of double quotes with the empty string in the column.

```{r}
tib_all <- mutate(tib_all,
                   RIAGENDR = as.factor(RIAGENDR),
                   RIDRETH1 = as.factor(RIDRETH1),
                   DMDBORN = gsub("\"", "", DMDBORN), # Remove quotes
                   DMDBORN = as.factor(DMDBORN),
                   OHXDECAY = (OHXDECAY == "Yes"),
                   OHXREST = (OHXREST == "Yes"))

```

## New variables

We need to create the variables mentioned in the paper are not directly present in NHANES.
For some variables such as country of birth, we could store the categories in `DMDBorn` but this way we can also keep the original distribution.  

```{r}
# Set columns to categories as in the paper
tib_all <- mutate(tib_all,

                    age.cat = cut(
                      RIDAGEYR,
                      breaks = c(13, 15, 18, 100),
                      include.lowest = TRUE,
                      labels = c("13-15", "16-18", "19+")),
                   
                    plasma.glucose.cat = case_when(
                     LBXGLU < 100 ~ "<100 mg/dl",
                     LBXGLU < 126 ~ ">=100 mg/dl and <126 mg/dl", 
                     LBXGLU >= 126 ~ ">=126 mg/dl",
                     .default = NA),
                   
                   hba1c.cat = case_when(
                     LBXGH < 5.7 ~ "<5.7%",
                     LBXGH >= 5.7 ~ ">=5.7% and <6.5%",
                     LBXGH >= 6.5 ~ ">= 6.5%",
                     .default = NA),
                   
                   bmi.cat = case_when( # If we were doing this from scratch we might also want an underweight category
                     BMXBMI < 25 ~ "Normal", 
                     BMXBMI < 30 ~ "Overweight",
                     BMXBMI >= 30 ~ "Obese",
                     .default = NA), 
                   
                   family.PIR.cat = case_when(
                     INDFMPIR == "PIR value greater than or equa" ~ ">= 1",
                     INDFMPIR == "Value greater than or equal to" ~ ">= 1",
                     as.numeric(INDFMPIR) >= 1 ~ ">=1",
                     as.numeric(INDFMPIR) < 1 ~ "<1",
                     .default = NA),
                   
                   birthplace = case_when(
                     DMDBORN == "Born in 50 US States or Washi" ~ "Within the US",
                     is.na(DMDBORN) ~ NA,
                     DMDBORN == "Don't Know" ~ NA,
                     DMDBORN == "Refused" ~ NA,
                    .default = "Outside the US"),
                   dental.caries = OHXDECAY | OHXREST)

```

::: {.callout-tip appearance="minimal"}
## Exercise

Add a `diabetes` column to the dataset based on the guidelines from Beheshti et. al:

>Individuals with an HbA1C of at least 6.5 percent
or a plasma-fasting glucose value of at least 126 mg/dl were
considered diabetics; prediabetics were those whose HbA1C
ranged from 5.7 percent to 6.4 percent and whose fasting
plasma glucose remained within 100 to 125 mg/dl; the remaining
study participants, who had less than 5.7 percent HbA1C
and less than 100 mg/dl fasting plasma glucose, were classified
as nondiabetics.

It is recommended to use `case_when`, but feel free to use any method you want. 

*Hint: remember to account for missing data! When should `diabetes` be `NA`?

```{r}
# Add diabetes column
tib_all <- tib_all |> 
          mutate(diabetes = case_when(
            is.na(LBXGH) & is.na(LBXGLU) ~ NA,
           LBXGH >= 6.5 | LBXGLU >= 126 ~ "diabetic",
           LBXGH >= 5.7 | LBXGLU >= 100 ~ "prediabetic",
            .default = "nondiabetic"))
```
:::



# Adding other diabetes data

While this is the data looked at in the paper, let's take a look at some other diabetes data from the same NHANES cycles. 

```{r}
load("nhanes_diabetes.RData")
```

This contains 4 variables from the DIQ table:

```{r}
DT::datatable(metadata_diabetes)
```

As before, we need to combine the three data cycles together.

```{r}
# This time let's combine the dataframes first
diabetes_all <- rbind(diabetes_d, diabetes_e, diabetes_f)

# And then convert to a tibble
diabetes_all <- as_tibble(diabetes_all) |>
  mutate(DIQ010 = as.factor(DIQ010),
         DIQ160 = as.factor(DIQ160),
         DIQ050 = as.factor(DIQ050)) |>
  select(-c(Begin.Year, EndYear))
```

We now need to combine the diabetes data with the rest of the nhanes data, adding in the new columns. 
This is a more complicated process than simply adding new rows to a dataset, as we need to determine which rows in the diabetes data are referencing the same participant as rows in the main data. 
This process is called joining or merging. 
To merge two datasets, we need to decide what to do with columns which appear in one dataset but not the other. 

We also need to determine which variable in the dataset we want to use as the **key** when joining, the column(s) that identifies which rows in the each dataset we want to match. 
In the `dplyr` join functions this is referred to as the `by` argument. 

In NHANES, we have the `SEQN` variable which uniquely identifies each participant in each survey cycle. 
We can use this as the key. 
In this case we want to perform join where we maintain all rows from the main dataset, but drop any rows which only exist in the diabetes dataset. 
Therefore, let's do a left join (with the main dataset on the left).

```{r}
tib_all <- left_join(tib_all, diabetes_all, by = "SEQN")
summary(tib_all)
```

Let's also check the number of `NA`'s in the new columns to make sure the data has matched up. 

```{r}
#Base R way
na_counts <- colSums(is.na(tib_all))
na_counts <- data.frame(na_counts[order(na_counts, decreasing = TRUE)])
colnames(na_counts) <- c("NA Count")
DT::datatable(na_counts)

# Tidyverse way
#tib_all |>
#  summarise_all(~sum(is.na(.)))
```

Unfortunately, it looks `DID040` won't be very useful. 

## Exploring Other Diabetes Variables

We'll start by checking the consistency of the DIQ variables. 
Was there anyone who said they were both diabetic and prediabetic?

```{r}
table(tib_all[,c("DIQ010", "DIQ160")], exclude = NULL)
```

Now let's see how much the diabetes definition by Beheshti agrees with the `DIQ` variables.

We'll make a variable with the same categories from the `DIQ` data. 
We'll leave out the borderline, don't know, and refused responses. 

```{r}
tib_all <- tib_all |> 
  mutate(diabetes.DIQ = case_when(
    DIQ010 == "Yes" ~ "diabetic",
    DIQ160 == "Yes" ~ "prediabetic",
    DIQ160 == "No" | DIQ010 == "No" ~ "nondiabetic"
  ))

table(tib_all[,c("diabetes.DIQ", "diabetes")])
```



# Replicating Beheshti Analysis

## Filter relevant population

We need to filter the summary population. 
Luckily, the paper provides total numbers of participants for most of the filtering steps performed. 
This makes it much easier for us to check our work. 

>The total number of individuals who participated in the
NHANES from 2005 to 2010 were 31,034 study-participants.
Among them, 3,660 were nonedentulous adolescents (aged 13
to 18 years old at the time of screening) who had exam survey
weights assigned. From those 3,660 adolescents, data to measure
the main outcome variable (dental caries experience) were
available for a final sample of 3,346 adolescents, representing
the population of 24,386,135 U.S. adolescents after applying
the NHANES sample weights, which was described and analyzed
in this study.

```{r}
tib_all <- tib_all |>
  mutate(in.study = (RIDAGEYR >= 13) & (RIDAGEYR <= 18) & !is.na(dental.caries)) # Gets the 3346 with non-NA dental carie variable

all_ado <- tib_all |>
  filter(in.study)
```

# Exploring the adolescent population

Let's see some statistics of our data. 

::: {.callout-tip appearance="minimal"}
## Exercise

Calculate the percent of adolescents with dental caries experience. 

```{r}
# Recall that you can sum boolean variables to get a count
sum(all_ado$dental.caries)/nrow(all_ado)
```
:::

### Summarize groups

We can use `group_by` and `summarize` to see summary statistics by various subgroups. 
For instance, let's take a look at dental caries and birthplace. 

```{r}
all_ado |>
  group_by(dental.caries, birthplace) |>
  summarize(n = n())
```
::: {.callout-tip appearance="minimal"}
## Summarizing

Calculate the percent of adolescents with dental caries for each birthplace category. 

```{r}
all_ado |>
  group_by(birthplace) |> # Group by birthplace
  summarize(n = n(), caries = sum(dental.caries)) |>
  mutate(perc_caries = caries/n)
```
:::

# Insulin

Let's look at the demographics of who's taking insulin by birthplace and family income. 

```{r}
tib_all |>
  filter(diabetes == "diabetic") |>
  group_by(birthplace, family.PIR.cat) |> 
  summarize(n = n(), insulin = sum((DIQ050) == "Yes")) |>
  mutate(perc_insulin = insulin/n)
```

We can also take a look at ethnicity.

```{r}
insulin_tbl <- tib_all |>
  filter(diabetes == "diabetic") |>
  group_by(RIDRETH1, birthplace) |> 
  summarize(n = n(), insulin = sum((DIQ050) == "Yes")) |>
  mutate(perc_insulin = insulin/n)
```
```{r}
ggplot(insulin_tbl, aes(x = birthplace, y = perc_insulin)) + 
  geom_bar(stat = "identity") + 
  facet_grid(~RIDRETH1)
```
# Summary statistics or visualization?

Summary statistics can compress datasets of any size into just a few numbers. 
This can be vital for understanding large amounts of data, but can also lead to misconceptions.
Let's take a look at a classic example, Anscombe's quartet. 

```{r}
library(datasets)
datasets::anscombe
```

First, we need to restructure this data so we can easily group it by each of the different 4 datasets included. 
We'll learn more about what the `pivot_longer` command does in the last week of class.
```{r}
# Let's restructure this data to have 3 variables, x, y, and the dataset number it belongs to
long_ans <- anscombe |>
  pivot_longer(
    everything(),
    cols_vary = "slowest",
    names_to = c(".value", "set"),
    names_pattern = "(.)(.)"
  )

```

Now we can visualize the 4 datasets easily using a `facet_wrap` in ggplot:

```{r}
ggplot(long_ans,aes(x=x,y=y,group=set))+geom_point()+facet_wrap(~set)
```
::: {.callout-tip appearance="minimal"}
# Exercise 

Calculate the mean and variance for x and y, and the correlation between x and y of each of the 4 sets of data. 

```{r}
long_ans |>
  group_by(set) |>
  summarise(mean_x = mean(x), mean_y = mean(y), variance_x = var(x), variance_y = var(y), correlation = cor(x, y))
```

:::

### Datasaurus

A similar example is in the `datasauRus` package in R. 

```{r}
library(datasauRus)

datasaurus_dozen |> 
  group_by(dataset) |> 
  summarize(
    mean_x    = mean(x),
    mean_y    = mean(y),
    std_dev_x = sd(x),
    std_dev_y = sd(y),
    corr_x_y  = cor(x, y)
  )
```

```{r}
library(ggplot2)
ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+
  geom_point()+
  theme_void()+
  theme(legend.position = "none")+
  facet_wrap(~dataset, ncol = 3)
```