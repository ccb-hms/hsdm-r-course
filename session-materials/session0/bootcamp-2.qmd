---
title: "Bootcamp Part 2: Starting with Data"
author: ""
format: 
  html: default
code-annotations: select
---

## Dataframes

We will begin with a mostly processed dataset from NHANES designed to examine the relationship between diabetes and dental caries in adolescents. Specifically, this dataset contains the 3346 adolescents recorded in NHANES from 2005 to 2010 with non-missing dental decay data.

We can load the data into R as a dataframe using the `read.csv` function. 

```{r}
nhanes <- read.csv("https://raw.githubusercontent.com/ccb-hms/hsdm-r-course/main/session-materials/session0/session0Data.csv")
```

This statement doesn't produce any output because, as you might
recall, assignments don't display anything. If we want to check that
our data has been loaded, we can see the contents of the data frame by
typing its name:

```{r, eval=FALSE}
nhanes
```

Wow... that was a lot of output. At least it means the data loaded
properly. Let's check the top (the first 6 lines) of this data frame
using the function `head()`:

```{r, purl=TRUE}
head(nhanes)
```

## What are data frames?

Data frames are the *de facto* data structure for most tabular data,
and what we use for statistics and plotting.

A data frame can be created by hand, but most commonly they are
generated by the functions `read.csv()` or `read.table()`; in other
words, when importing spreadsheets from your hard drive (or the web).

A data frame is the representation of data in the format of a table
where the columns are vectors that all have the same length. Because
columns are vectors, each column must contain a single type of data
(e.g., characters, integers, factors).

We can see this when inspecting the <b>str</b>ucture of a data frame
with the function `str()`:

```{r}
str(nhanes)
```

## Inspecting `data.frame` Objects

We already saw how the functions `head()` and `str()` can be useful to
check the content and the structure of a data frame. Here is a
non-exhaustive list of functions to get a sense of the
content/structure of the data. Let's try them out!

**Size**:

- `dim(nhanes)` - returns a vector with the number of rows as the first
  element, and the number of columns as the second element (the
  **dim**ensions of the object).
- `nrow(nhanes)` - returns the number of rows.
- `ncol(nhanes)` - returns the number of columns.

**Content**:

- `head(nhanes)` - shows the first 6 rows.
- `tail(nhanes)` - shows the last 6 rows.

**Names**:

- `names(nhanes)` - returns the column names (synonym of `colnames()` for
  `data.frame` objects).
- `rownames(nhanes)` - returns the row names.

**Summary**:

- `str(nhanes)` - structure of the object and information about the
  class, length and content of each column.
- `summary(nhanes)` - summary statistics for each column.

Note: most of these functions are "generic", they can be used on other types of
objects besides `data.frame`.

## Packages

Bracket subsetting is handy, but it can be cumbersome and difficult to
read, especially for complicated operations.

Some packages can greatly facilitate our task when we manipulate data.
Packages in R are basically sets of additional functions that let you
do more stuff. The functions we've been using so far, like `str()` or
`data.frame()`, come built into R; Loading packages can give you access to other
specific functions. Before you use a package for the first time you need to install
it on your machine, and then you should import it in every subsequent
R session when you need it.

- The package **`dplyr`** provides powerful tools for data manipulation tasks.
  It is built to work directly with data frames, with many manipulation tasks
  optimised.

- As we will see latter on, sometimes we want a data frame to be reshaped to be able
  to do some specific analyses or for visualisation. The package **`tidyr`** addresses
  this common problem of reshaping data and provides tools for manipulating
  data in a tidy way.

To learn more about **`dplyr`** and **`tidyr`** after the workshop,
you may want to check out this [handy data transformation with
**`dplyr`**
cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-transformation.pdf)
and this [one about
**`tidyr`**](https://raw.githubusercontent.com/rstudio/cheatsheets/main/tidyr.pdf).

- The **`tidyverse`** package is an "umbrella-package" that installs
  several useful packages for data analysis which work well together,
  such as **`tidyr`**, **`dplyr`**, **`ggplot2`**, **`tibble`**, etc.
  These packages help us to work and interact with the data.
  They allow us to do many things with your data, such as subsetting, transforming,
  visualising, etc.

Packages can be installed using the `install.packages` command. 
This downloads and installs the package into your **entire R installation**. 
This means that you would not need to re-install the package for a new project.  

```{r, eval=FALSE, purl=TRUE}
install.packages("tidyverse")
```

Once a package is installed, it can be loaded using the `library` function. 
This tells R to use all of the functions inside the loaded package. 
`library` loads packages into your R session, and thus this line needs to be run each time you open R. 

```{r, message=FALSE, purl=TRUE}
## load the tidyverse packages, incl. dplyr
library("tidyverse")
library("DT")
```

## Loading data with tidyverse

Instead of `read.csv()`, we will read in our data using the `read_csv()`
function (notice the `_` instead of the `.`), from the tidyverse package
**`readr`**.

```{r, message=FALSE, purl=TRUE}
nhanes <- read_csv("https://raw.githubusercontent.com/ccb-hms/hsdm-r-course/main/session-materials/session0/session0Data.csv")

## view the data
datatable(nhanes)
```

Notice that the class of the data is now referred to as a "tibble".

Tibbles tweak some of the behaviors of the data frame objects we introduced in the
previously. The data structure is very similar to a data frame. For our purposes
the only differences are that:

1. It displays the data type of each column under its name.
  Note that \<`dbl`\> is a data type defined to hold numeric values with
  decimal points.

2. It only prints the first few rows of data and only as many columns as fit on
  one screen.

We are now going to learn some of the most common **`dplyr`** functions:

- `select()`: subset columns
- `filter()`: subset rows on conditions
- `mutate()`: create new columns by using information from other columns
- `group_by()` and `summarise()`: create summary statistics on grouped data
- `arrange()`: sort results
- `count()`: count discrete values

## Selecting columns and filtering rows

To select columns of a data frame, use `select()`. The first argument
to this function is the data frame (`nhanes`), and the subsequent
arguments are the columns to keep.

```{r, purl=TRUE}
select(nhanes, sex, age.years, dental.decay.present, hba1c)
```

To select all columns *except* certain ones, put a "-" in front of
the variable to exclude it.

```{r, purl=TRUE}
select(nhanes, -sequence.id, -family.PIR)
```

This will select all the variables in `nhanes` except `sequence.id`
and `family.PIR`.

To choose rows based on a specific criteria, use `filter()`:

```{r, purl=TRUE}
filter(nhanes, sex == "Male")
filter(nhanes, sex == "Male" & plasma.glucose > 80)
filter(nhanes, sex == "Male" & !is.na(hba1c))
```

## Pipes

What if you want to select and filter at the same time? There are three
ways to do this: use intermediate steps, nested functions, or pipes.

With intermediate steps, you create a temporary data frame and use
that as input to the next function, like this:

```{r, purl=TRUE}
nhanes2 <- filter(nhanes, sex == "Male")
nhanes3 <- select(nhanes2, sex, age.years, dental.decay.present, hba1c)
nhanes3
```

This is readable, but can clutter up your workspace with lots of
intermediate objects that you have to name individually. With multiple
steps, that can be hard to keep track of.

You can also nest functions (i.e. one function inside of another),
like this:

```{r, purl=TRUE}
nhanes3 <- select(filter(nhanes, sex == "Male"), sex, age.years, dental.decay.present, hba1c)
nhanes3
```

This is handy, but can be difficult to read if too many functions are nested, as
R evaluates the expression from the inside out (in this case, filtering, then selecting).

The last option, *pipes*, are a recent addition to R. Pipes let you take
the output of one function and send it directly to the next, which is useful
when you need to do many things to the same dataset.

Pipes in R look like `%>%` (made available via the **`magrittr`**
package) or `|>` (through base R). If you use RStudio, you can type
the pipe with <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you
have a PC or <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>M</kbd> if you
have a Mac.

In the above code, we use the pipe to send the `nhanes` dataset first
through `filter()` to keep rows where `sex` is Male, then through
`select()` to keep only the selected columns.

The pipe `%>%` takes the object on its left and passes it directly as
the first argument to the function on its right, we don't need to
explicitly include the data frame as an argument to the `filter()` and
`select()` functions any more.

```{r, purl=TRUE}
nhanes %>%
  filter(sex == "Male") %>%
  select(sex, age.years, dental.decay.present, hba1c)
```

Some may find it helpful to read the pipe like the word "then". For instance,
in the above example, we took the data frame `rna`, *then* we `filter`ed
for rows with `sex == "Male"`, *then* we `select`ed columns `sex`, `age.years`, `dental.decay.present`, and `hba1c`.

The **`dplyr`** functions by themselves are somewhat simple, but by
combining them into linear workflows with the pipe, we can accomplish
more complex manipulations of data frames.

If we want to create a new object with this smaller version of the data, we
can assign it a new name:

```{r, purl=TRUE}
nhanes3 %>%
  filter(sex == "Male") %>%
  select(sex, age.years, dental.decay.present, hba1c)

nhanes3
```

::: {.callout-note icon=false}

## Challenge:

Using pipes, subset the `nhanes` data to keep female participants 15 years or older,
where the hba1c is greater than 5.2 (and is not `NA`), and retain only the columns `sex`, `age.years`, and `plasma.glucose`.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r}
nhanes %>%
  filter(hba1c > 5.2,
         sex == "Female",
         age.years >= 15 ) %>%
  select(sex, age.years, plasma.glucose)
```



:::

## Mutate

Frequently you'll want to create new columns based on the values of existing
columns, for example to do unit conversions, or to find the ratio of values in two
columns. For this we'll use `mutate()`.

To create a new column of age in months:

```{r, purl=TRUE}
nhanes %>%
  mutate(age.months = age.years * 12) %>%
  select(age.months, age.years)
```

You can also create a second new column based on the first new column within the same call of `mutate()`:

```{r, purl=TRUE}
nhanes %>%
  mutate(age.months = age.years * 12,
         lived_200_months = age.months >= 200) %>%
  select(age.months, age.years, lived_200_months)
```

::: {.callout-note icon=false}

## Challenge

Create a new data frame from the `nhanes` data that meets the following
criteria: contains the columns `sex`, `under_14`,
`ethnicity`, and `family.PIR` columns. The `under_14` column should be a logical variable indicating whether or not the age of the participant is less than 14. This data frame must
only contain participants born in the USA or Mexico, have a non-missing plasma glucose value, and with a BMI less than 30.

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r, eval=TRUE, purl=TRUE}
nhanes %>%
  mutate(under_14 = age.years < 14) %>%
  filter(birthplace == 'Born in 50 US States or Washi' | birthplace == "Born in Mexico") %>%
  filter(!is.na(plasma.glucose)) %>%
  filter(bmi < 30) %>%
  select(sex, under_14, ethnicity, family.PIR)
```



:::

## Split-apply-combine data analysis

Many data analysis tasks can be approached using the
*split-apply-combine* paradigm: split the data into groups, apply some
analysis to each group, and then combine the results. **`dplyr`**
makes this very easy through the use of the `group_by()` function.

```{r}
nhanes %>%
  group_by(birthplace)
```

The `group_by()` function doesn't perform any data processing, it
groups the data into subsets: in the example above, our initial
`tibble` of `r nrow(nhanes)` observations is split into
`r length(unique(nhanes$birthplace))` groups based on the `birthplace` variable.

We could similarly decide to group the tibble by sex:

```{r}
nhanes %>%
  group_by(sex)
```

Here our initial `tibble` of `r nrow(nhanes)` observations is split into
`r length(unique(nhanes$sex))` groups based on the `sex` variable.

Once the data has been grouped, subsequent operations will be
applied on each group independently.

### The `summarise()` function

`group_by()` is often used together with `summarise()`, which
collapses each group into a single-row summary of that group.

`group_by()` takes as arguments the column names that contain the
**categorical** variables for which you want to calculate the summary
statistics. So to compute the mean `bmi` by birthplace:

```{r}
nhanes %>%
  group_by(birthplace) %>%
  summarise(mean_bmi = mean(bmi, na.rm = TRUE))
```

But we can can also group by multiple columns:

```{r}
nhanes %>%
  group_by(sex, ethnicity) %>%
  summarise(mean_bmi = mean(bmi, na.rm = TRUE))
```

Once the data is grouped, you can also summarise multiple variables at the same
time (and not necessarily on the same variable). For instance, we could add a
column indicating the median `plasma.glucose` by sex and ethnicity:

```{r, purl=TRUE}
nhanes %>%
  group_by(sex, ethnicity) %>%
  summarise(mean_plasma_glucose = mean(plasma.glucose),
            median_plasma_glucose = median(plasma.glucose))
```

::: {.callout-note icon=false}

## Challenge

Calculate the mean `hba1c` of participants born in the USA by age.

:::


::: {.callout-tip icon=false collapse=true}

## Solution

```{r, purl=TRUE}
nhanes %>%
  filter(birthplace == 'Born in 50 US States or Washi') %>%
  group_by(age.years) %>%
  summarise(mean_hba1c = mean(hba1c))
```

:::

### Counting

When working with data, we often want to know the number of observations found
for each factor or combination of factors. For this task, **`dplyr`** provides
`count()`. For example, if we wanted to count the number of rows of data for
each age, we would do:

```{r, purl=TRUE}
nhanes %>%
    count(age.years)
```

The `count()` function is shorthand for something we've already seen: grouping by a variable, and summarising it by counting the number of observations in that group. In other words, `nhanes %>% count(age.years)` is equivalent to:

```{r, purl=TRUE}
nhanes %>%
    group_by(age.years) %>%
    summarise(n = n())
```

The previous example shows the use of `count()` to count the number of rows/observations
for *one* factor (i.e., `infection`).
If we wanted to count a *combination of factors*, such as `age` and `sex`,
we would specify the first and the second factor as the arguments of `count()`:

```{r, purl=TRUE}
nhanes %>%
    count(age.years, sex)
```

It is sometimes useful to sort the result to facilitate the comparisons.
We can use `arrange()` to sort the table.
For instance, we might want to arrange the table above by age:

```{r, purl=TRUE}
nhanes %>%
    count(age.years, sex) %>%
    arrange(age.years)
```

or by counts:

```{r, purl=TRUE}
nhanes %>%
    count(age.years, sex) %>%
    arrange(n)
```

To sort in descending order, we need to add the `desc()` function:

```{r, purl=TRUE}
nhanes %>%
    count(age.years, sex) %>%
    arrange(desc(n))
```

::: {.callout-note icon=false}

## Challenge

1. How many participants have a non-empty plasma glucose value for each age?
2. Use `group_by()` and `summarise()` to evaluate the poverty income ratio (`family.PIR`) by ethnicity. Which ethnicity has the highest poverty income ratio?

:::

::: {.callout-tip icon=false collapse=true}

## Solution

```{r}
#1
nhanes %>% filter(!is.na(plasma.glucose)) %>%
  group_by(age.years) %>%
  count()

#2
nhanes %>% group_by(ethnicity) %>%
  summarise(mean_PIR = mean(family.PIR, na.rm = TRUE)) %>%
  arrange(desc(mean_PIR))
```


:::

## Exporting data

Now that you have learned how to use `dplyr` to extract information from
or summarise your raw data, you may want to export these new data sets to share
them with your collaborators or for archival.

Similar to the `read_csv()` function used for reading CSV files into R, there is
a `write_csv()` function that generates CSV files from data frames.

Before using `write_csv()`, we are going to create a new folder, `data_output`,
in our working directory that will store this generated dataset. We don't want
to write generated datasets in the same directory as our raw data.
It's good practice to keep them separate. The `data` folder should only contain
the raw, unaltered data, and should be left alone to make sure we don't delete
or modify it. In contrast, our script will generate the contents of the `data_output`
directory, so even if the files it contains are deleted, we can always
re-generate them.

Let's use `write_csv()` to save the nhanes data.

```{r, purl=TRUE, eval=FALSE}
write_csv(nhanes, file = "nhanes_processed.csv")
```


------------------------------------------------------------------------

*The materials in this lesson have been adapted from work created by the (HBC)\](http://bioinformatics.sph.harvard.edu/) and Data Carpentry (http://datacarpentry.org/), as well as materials created by Laurent Gatto, Charlotte Soneson, Jenny Drnevich, Robert Castelo, and Kevin Rue-Albert. These are open access materials distributed under the terms of the [Creative Commons Attribution license](https://creativecommons.org/licenses/by/4.0/) (CC BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.*